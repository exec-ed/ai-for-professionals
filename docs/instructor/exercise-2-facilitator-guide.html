<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Exercise 2 Facilitator Guide | AI for Professionals</title>
  <link rel="stylesheet" href="../css/shared.css">
  <link rel="stylesheet" href="../css/materials.css">
  <script src="../js/auth.js"></script>
  <meta name="robots" content="noindex, nofollow">
</head>
<body onload="checkAuth()">
  <header>
    <nav class="container">
      <a href="../index.html" class="logo">AI for Professionals</a>
      <ul class="nav-links">
        <li><a href="../materials.html">Materials</a></li>
        <li><a href="index.html" style="color: #e74c3c;">Instructor</a></li>
      </ul>
    </nav>
  </header>

  <main class="container" id="protected-content" style="display:none;">
    <article class="material-content">
      <header class="material-header">
        <h1>Exercise 2 Facilitator Guide</h1>
        <div class="material-meta">
          <span style="color: #e74c3c; font-weight: 600;">Password-Protected Instructor Material</span>
          <button onclick="window.print()" class="btn-primary" style="cursor: pointer; border: none;">Print to PDF</button>
        </div>
      </header>

            <nav id="toc" class="toc">
        <h2>Contents</h2>
        <ul>
        <li><a
        href="#exercise-2-prompt-engineering-workshop-facilitator-guide"
        id="toc-exercise-2-prompt-engineering-workshop-facilitator-guide">Exercise
        2: Prompt Engineering Workshop — Facilitator Guide</a>
        <ul>
        <li><a href="#pre-exercise-setup"
        id="toc-pre-exercise-setup">Pre-Exercise Setup</a></li>
        <li><a href="#the-exercise-structure"
        id="toc-the-exercise-structure">The Exercise Structure</a></li>
        <li><a href="#setup-5-min-1125-am"
        id="toc-setup-5-min-1125-am">Setup (5 min) — 11:25 AM</a></li>
        <li><a href="#round-1-baseline-15-min-1130-am"
        id="toc-round-1-baseline-15-min-1130-am">Round 1: Baseline (15
        min) — 11:30 AM</a></li>
        <li><a href="#round-2-apply-rtcf-20-min-1145-am"
        id="toc-round-2-apply-rtcf-20-min-1145-am">Round 2: Apply RTCF
        (20 min) — 11:45 AM</a></li>
        <li><a href="#round-3-advanced-techniques-15-min-1205-pm"
        id="toc-round-3-advanced-techniques-15-min-1205-pm">Round 3:
        Advanced Techniques (15 min) — 12:05 PM</a></li>
        <li><a href="#debrief-10-min-1220-pm"
        id="toc-debrief-10-min-1220-pm">Debrief (10 min) — 12:20
        PM</a></li>
        <li><a href="#common-facilitation-moves"
        id="toc-common-facilitation-moves">Common Facilitation
        Moves</a></li>
        <li><a href="#success-indicators"
        id="toc-success-indicators">Success Indicators</a></li>
        <li><a href="#your-checklist" id="toc-your-checklist">Your
        Checklist</a></li>
        </ul></li>
        </ul>
      </nav>
      
      <div class="content">
        <h1
        id="exercise-2-prompt-engineering-workshop-facilitator-guide">Exercise
        2: Prompt Engineering Workshop — Facilitator Guide</h1>
        <p><strong>Duration:</strong> 60 minutes (11:30 AM - 12:30 PM)
        <strong>Frameworks used:</strong> RTCF Prompt Framework
        <strong>Core learning:</strong> Structured prompts produce
        dramatically better output than naive ones. The quality of your
        input determines the quality of your output.</p>
        <hr />
        <h2 id="pre-exercise-setup">Pre-Exercise Setup</h2>
        <p><strong>Materials needed:</strong> - Prompt Engineering
        Worksheet (1 per participant, printed) - Frameworks Reference
        Sheet (already distributed) - Projector showing RTCF framework
        as a reminder</p>
        <p><strong>Room check:</strong> - Participants should already
        have AI tools open from Exercise 1 - RTCF framework should be
        clearly visible (projector or whiteboard)</p>
        <hr />
        <h2 id="the-exercise-structure">The Exercise Structure</h2>
        <p>Three rounds, each building on the previous:</p>
        <table>
        <colgroup>
        <col style="width: 20%" />
        <col style="width: 17%" />
        <col style="width: 37%" />
        <col style="width: 25%" />
        </colgroup>
        <thead>
        <tr>
        <th>Round</th>
        <th>Time</th>
        <th>What Happens</th>
        <th>Purpose</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><strong>Round 1: Baseline</strong></td>
        <td>15 min</td>
        <td>Naive prompts → see what you get</td>
        <td>Feel the pain of vague prompting</td>
        </tr>
        <tr>
        <td><strong>Round 2: Apply RTCF</strong></td>
        <td>20 min</td>
        <td>Structured prompts → compare improvement</td>
        <td>Experience the framework’s value</td>
        </tr>
        <tr>
        <td><strong>Round 3: Advanced</strong></td>
        <td>15 min</td>
        <td>Chain-of-thought, iteration, multi-turn</td>
        <td>Stretch skills further</td>
        </tr>
        <tr>
        <td><strong>Debrief</strong></td>
        <td>10 min</td>
        <td>Share best prompts, discuss lessons</td>
        <td>Consolidate learning</td>
        </tr>
        </tbody>
        </table>
        <hr />
        <h2 id="setup-5-min-1125-am">Setup (5 min) — 11:25 AM</h2>
        <p>Distribute the Prompt Engineering Worksheet (if not already
        distributed).</p>
        <p><strong>Your script:</strong></p>
        <blockquote>
        <p>“You have a worksheet with 6 workplace scenarios. Each one
        gives you a realistic situation and enough context to write a
        good prompt. Here’s how this works:</p>
        <p><strong>Round 1:</strong> Pick 3 scenarios. For each one,
        write the prompt you’d naturally write — the first thing that
        comes to mind. Type it into your AI tool and note the quality of
        the output. Don’t try to be fancy. Write what you’d normally
        write.</p>
        <p><strong>Round 2:</strong> Go back to the same 3 scenarios.
        This time, use the RTCF framework — Role, Task, Context, Format.
        Rewrite your prompts and compare the output to Round 1.</p>
        <p><strong>Round 3:</strong> Pick your best scenario and try an
        advanced technique — I’ll explain those when we get there.</p>
        <p>The goal is to feel the difference between a lazy prompt and
        a structured one. Ready? Start Round 1 now.”</p>
        </blockquote>
        <hr />
        <h2 id="round-1-baseline-15-min-1130-am">Round 1: Baseline (15
        min) — 11:30 AM</h2>
        <p><strong>What participants do:</strong> Choose 3 of 6
        scenarios, write quick natural prompts, note output quality.</p>
        <p><strong>Your role:</strong> Circulate and observe. <strong>Do
        not help them write better prompts yet.</strong> This round is
        about experiencing the gap.</p>
        <p><strong>What you’re looking for:</strong></p>
        <table>
        <colgroup>
        <col style="width: 30%" />
        <col style="width: 70%" />
        </colgroup>
        <thead>
        <tr>
        <th>Sign</th>
        <th>What It Means</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>“This is pretty generic”</td>
        <td>They’re noticing the problem — good</td>
        </tr>
        <tr>
        <td>“It didn’t include [thing I needed]”</td>
        <td>They didn’t give context — they’ll see why in Round 2</td>
        </tr>
        <tr>
        <td>“Actually this is decent”</td>
        <td>Some tasks with simple requirements do get decent output
        from naive prompts — that’s real too</td>
        </tr>
        <tr>
        <td>Frustration</td>
        <td>Good — they’ll appreciate the framework more</td>
        </tr>
        </tbody>
        </table>
        <p><strong>Things to say while circulating:</strong> - “Don’t
        worry about quality yet — just note what you get” - “Rate it
        honestly: would you send this as-is?” - “Save your Round 1
        output — you’ll compare it to Round 2”</p>
        <p><strong>Don’t:</strong> - Suggest improvements to their
        prompts (not yet) - Help them rewrite (that’s Round 2) - Spend
        too long at one table — keep moving</p>
        <p><strong>At 11:45, call time:</strong></p>
        <blockquote>
        <p>“Stop where you are. You should have tried at least 2
        scenarios. How was the output? [Take a few quick reactions —
        don’t spend more than 1 minute on this.] Now let’s see what
        happens when we add structure.”</p>
        </blockquote>
        <hr />
        <h2 id="round-2-apply-rtcf-20-min-1145-am">Round 2: Apply RTCF
        (20 min) — 11:45 AM</h2>
        <p><strong>Your script:</strong></p>
        <blockquote>
        <p>“Go back to the same scenarios. This time, use the RTCF
        framework. For each prompt, fill in the table on your
        worksheet:</p>
        <ul>
        <li><strong>Role:</strong> Who should the AI be? Be specific —
        not just ‘a writer’ but ‘a senior project manager with
        experience communicating with executives.’</li>
        <li><strong>Task:</strong> What exactly should it do? Include
        the verb and the scope.</li>
        <li><strong>Context:</strong> What does the AI need to know?
        Audience, background, constraints, tone.</li>
        <li><strong>Format:</strong> How should the output look? Bullet
        points, table, email format, word count.</li>
        </ul>
        <p>Same scenarios. Same AI tools. Different prompts. Go.”</p>
        </blockquote>
        <p><strong>Your role:</strong> Now you can help. Circulate
        and:</p>
        <p><strong>Coach prompt-writing:</strong> - “What’s missing from
        your Context? Who’s the audience?” - “Your Task is still pretty
        vague — what specifically should the AI produce?” - “Try adding
        a Format — right now you’re letting the AI decide how to
        structure the output”</p>
        <p><strong>Spot great examples:</strong> - When someone gets a
        dramatically better result, ask if you can share it in the
        debrief - Note which RTCF components made the biggest difference
        for different scenarios</p>
        <p><strong>Watch for common mistakes:</strong> | Mistake | Your
        Coaching Move | |———|——————-| | Role is too generic (“You are an
        expert”) | “Expert in what? The more specific, the more it
        shifts the output” | | Task is a topic, not an action (“About
        the project delay”) | “What should the AI DO with the project
        delay? Summarise? Draft an email? Create a plan?” | | Context is
        missing entirely | “Imagine you’re briefing a brand-new
        colleague. What would they need to know to do this task?” | |
        Format is missing | “If I sent you this output, how would you
        want it structured? Tell the AI that.” | | Prompt is 3
        paragraphs long | “Good — detailed is better than vague. But
        check: is everything in there necessary?” |</p>
        <p><strong>At 12:05, call time:</strong></p>
        <blockquote>
        <p>“Finish the prompt you’re working on. Compare your Round 1
        and Round 2 outputs side by side. How big is the
        difference?”</p>
        </blockquote>
        <p><strong>Quick pulse check (1 minute):</strong></p>
        <blockquote>
        <p>“Hands up if your Round 2 output was significantly better
        than Round 1.” [Most hands should go up.]</p>
        <p>“Hands up if there was barely any difference.” [If anyone
        raises a hand: “Interesting — let’s look at your prompts during
        the debrief. You may have been naturally detailed in Round 1, or
        there might be something we can tweak.”]</p>
        </blockquote>
        <hr />
        <h2 id="round-3-advanced-techniques-15-min-1205-pm">Round 3:
        Advanced Techniques (15 min) — 12:05 PM</h2>
        <p><strong>Your script:</strong></p>
        <blockquote>
        <p>“Now pick your best scenario — the one where you got the best
        Round 2 result. We’re going to push further with three advanced
        techniques. Try at least one:</p>
        <p><strong>Technique 1: Chain-of-thought.</strong> Before the AI
        writes the output, ask it to think through the problem step by
        step. For example: ‘Before writing the email, think step-by-step
        about what David is really concerned about, what his priorities
        are, and what tone would be most effective. Then write the
        email.’</p>
        <p><strong>Technique 2: Multiple versions.</strong> Ask the AI
        to generate 2-3 different versions and explain the trade-offs.
        ‘Write three versions of this email: one that’s very direct, one
        that’s empathetic, and one that’s diplomatic. Then tell me which
        you’d recommend and why.’</p>
        <p><strong>Technique 3: Self-critique.</strong> After getting an
        output, ask the AI to evaluate its own work. ‘Review what you
        just wrote. What’s weak? What would a senior executive find
        unconvincing? Rewrite to fix those issues.’</p>
        <p>Try one. See what happens.”</p>
        </blockquote>
        <p><strong>Your role:</strong> This round is more exploratory.
        Let them experiment.</p>
        <p><strong>For advanced participants:</strong> Challenge them to
        combine techniques — chain-of-thought AND self-critique, for
        example.</p>
        <p><strong>For struggling participants:</strong> Suggest
        Technique 2 (multiple versions) as the easiest to try — it just
        requires adding one sentence to their existing prompt.</p>
        <hr />
        <h2 id="debrief-10-min-1220-pm">Debrief (10 min) — 12:20 PM</h2>
        <p><strong>Question 1: “What was the single biggest improvement
        from Round 1 to Round 2?”</strong></p>
        <p>Listen for: - “The output was actually usable instead of
        generic” - “It got the tone right because I told it who the
        audience was” - “Adding format meant I could paste it straight
        into my document”</p>
        <p><strong>Your move:</strong> Draw out 3-4 examples. Ask:
        “Which RTCF component made the most difference?” (Usually
        Context or Format.)</p>
        <p><strong>Question 2: “Did anyone find a scenario where RTCF
        didn’t help much?”</strong></p>
        <p>Listen for: - Very simple tasks where a naive prompt was
        already sufficient - Tasks where the AI lacks real knowledge
        regardless of prompting</p>
        <p><strong>Your move:</strong> Validate this. “Not every task
        needs all four components. A simple ‘summarise this into 3
        bullet points’ might only need Task and Format. The framework is
        a tool, not a rule.”</p>
        <p><strong>Question 3: “What happened in Round 3?”</strong></p>
        <p>Listen for: - Chain-of-thought produced more nuanced
        responses - Multiple versions revealed options they hadn’t
        considered - Self-critique caught issues they would have
        missed</p>
        <p><strong>Your move:</strong> Highlight that iteration is the
        real skill. “The best prompters don’t write one perfect prompt —
        they write a good prompt, evaluate the output, and refine. It’s
        a conversation, not a command.”</p>
        <p><strong>Close the debrief:</strong></p>
        <blockquote>
        <p>“Before lunch, I want you to do one thing: save your best
        prompt from today into the template library at the bottom of
        your worksheet. This is the start of your personal prompt
        collection. Over time, you’ll build a library of templates for
        your common tasks.”</p>
        </blockquote>
        <hr />
        <h2 id="common-facilitation-moves">Common Facilitation
        Moves</h2>
        <table>
        <colgroup>
        <col style="width: 50%" />
        <col style="width: 50%" />
        </colgroup>
        <thead>
        <tr>
        <th>Situation</th>
        <th>Your Move</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>Someone’s Round 2 isn’t much better than Round 1</td>
        <td>Look at their prompts together — usually Context or Role is
        still missing. Coach in real-time.</td>
        </tr>
        <tr>
        <td>Someone gets a perfect Round 1 output</td>
        <td>Ask: “Were you already applying structure naturally? That’s
        a strength. Try a harder scenario.”</td>
        </tr>
        <tr>
        <td>A table is working silently</td>
        <td>Prompt discussion: “Share your Round 1 vs Round 2 with your
        neighbour. What’s different?”</td>
        </tr>
        <tr>
        <td>Someone is trying all 6 scenarios</td>
        <td>Redirect: “Depth over breadth — pick 3 and really refine
        them.”</td>
        </tr>
        <tr>
        <td>The room is high-energy, lots of sharing</td>
        <td>Let it run. This is the best part of the exercise.</td>
        </tr>
        <tr>
        <td>Someone’s AI gave an offensive or biased response</td>
        <td>Address it: “This is real. AI reflects patterns from its
        training data, including biases. What would you do if this
        happened at work?”</td>
        </tr>
        </tbody>
        </table>
        <hr />
        <h2 id="success-indicators">Success Indicators</h2>
        <ul class="task-list">
        <li><label><input type="checkbox" />Clear, visible improvement
        from Round 1 to Round 2 for most participants</label></li>
        <li><label><input type="checkbox" />Participants can name which
        RTCF component made the biggest difference</label></li>
        <li><label><input type="checkbox" />At least some participants
        tried and benefited from Round 3 techniques</label></li>
        <li><label><input type="checkbox" />The debrief generated
        sharing of specific prompts (not just general
        impressions)</label></li>
        <li><label><input type="checkbox" />Participants saved at least
        one prompt to their template library</label></li>
        </ul>
        <hr />
        <h2 id="your-checklist">Your Checklist</h2>
        <p><strong>Before (11:20 AM):</strong> - [ ] Worksheets
        distributed - [ ] RTCF framework visible on projector or
        whiteboard - [ ] Confirmed all participants have working AI tool
        access</p>
        <p><strong>During:</strong> - [ ] Did NOT help during Round 1
        (let them feel the gap) - [ ] Actively coached during Round 2
        (helped with RTCF application) - [ ] Circulated to all tables
        during each round - [ ] Noted strong examples for the
        debrief</p>
        <p><strong>After:</strong> - [ ] Debriefed with all three
        questions - [ ] Prompted participants to save best prompt to
        template library - [ ] Connected to afternoon: “You’ll use RTCF
        again in the data analysis exercise”</p>
      </div>

      <footer class="material-footer">
        <p>
          <a href="index.html">Back to Instructor Materials</a> |
          <a href="../materials.html">Public Materials</a> |
          <a href="#" onclick="logout(); return false;" style="color: #e74c3c;">Logout</a>
        </p>
      </footer>
    </article>
  </main>

  <footer class="site-footer">
    <div class="container">
      <p><strong>AI for Professionals Workshop</strong></p>
      <p style="margin-top: 0.5rem; opacity: 0.8;">Executive Education | Curtin Business School</p>
      <p style="margin-top: 1rem;"><a href="mailto:michael.borck@curtin.edu.au">michael.borck@curtin.edu.au</a></p>
    </div>
  </footer>
</body>
</html>
